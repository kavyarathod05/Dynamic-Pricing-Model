{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e3e008-8a9c-43de-bbc6-e7d569d4caa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Inventory Level</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Units Ordered</th>\n",
       "      <th>Demand Forecast</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Weather Condition</th>\n",
       "      <th>Competitor Pricing</th>\n",
       "      <th>Seasonality</th>\n",
       "      <th>Base Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>231</td>\n",
       "      <td>127</td>\n",
       "      <td>55</td>\n",
       "      <td>135.47</td>\n",
       "      <td>33.50</td>\n",
       "      <td>20</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>29.69</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>25.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0002</td>\n",
       "      <td>204</td>\n",
       "      <td>150</td>\n",
       "      <td>66</td>\n",
       "      <td>144.04</td>\n",
       "      <td>63.01</td>\n",
       "      <td>20</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>66.16</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>47.2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0003</td>\n",
       "      <td>102</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>74.02</td>\n",
       "      <td>27.99</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>31.32</td>\n",
       "      <td>Summer</td>\n",
       "      <td>20.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0004</td>\n",
       "      <td>469</td>\n",
       "      <td>61</td>\n",
       "      <td>164</td>\n",
       "      <td>62.18</td>\n",
       "      <td>32.72</td>\n",
       "      <td>10</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>34.74</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>24.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0005</td>\n",
       "      <td>166</td>\n",
       "      <td>14</td>\n",
       "      <td>135</td>\n",
       "      <td>9.26</td>\n",
       "      <td>73.64</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>68.95</td>\n",
       "      <td>Summer</td>\n",
       "      <td>55.2300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Store ID Product ID  Inventory Level  Units Sold  Units Ordered  \\\n",
       "0  2022-01-01     S001      P0001              231         127             55   \n",
       "1  2022-01-01     S001      P0002              204         150             66   \n",
       "2  2022-01-01     S001      P0003              102          65             51   \n",
       "3  2022-01-01     S001      P0004              469          61            164   \n",
       "4  2022-01-01     S001      P0005              166          14            135   \n",
       "\n",
       "   Demand Forecast  Price  Discount Weather Condition  Competitor Pricing  \\\n",
       "0           135.47  33.50        20             Rainy               29.69   \n",
       "1           144.04  63.01        20             Sunny               66.16   \n",
       "2            74.02  27.99        10             Sunny               31.32   \n",
       "3            62.18  32.72        10            Cloudy               34.74   \n",
       "4             9.26  73.64         0             Sunny               68.95   \n",
       "\n",
       "  Seasonality  Base Cost  \n",
       "0      Autumn    25.1250  \n",
       "1      Autumn    47.2575  \n",
       "2      Summer    20.9925  \n",
       "3      Autumn    24.5400  \n",
       "4      Summer    55.2300  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df=pd.read_csv('retail_store_inventory.csv')\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "df.drop(columns=['Category','Region'], inplace=True)\n",
    "\n",
    "df.drop(columns=['Holiday/Promotion'], inplace=True)\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dce0106-f310-4be4-927b-83de94e6887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature and target separation\n",
    "X = df.drop(['Discount', 'Demand Forecast'], axis=1)\n",
    "y_discount = df['Discount']\n",
    "y_demand = df['Demand Forecast']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['Store ID', 'Product ID', 'Weather Condition', 'Seasonality']\n",
    "numerical_cols = ['Inventory Level', 'Units Sold', 'Units Ordered', 'Price', 'Competitor Pricing']\n",
    "\n",
    "# Define preprocessor (only fit once)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98f780a-c0d6-4530-aeba-2dc92aa2d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14620, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train_d, y_test_d = train_test_split(X, y_discount, test_size=0.2, random_state=42)\n",
    "_, _, y_train_f, y_test_f = train_test_split(X, y_demand, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit preprocessor on the entire training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Use the same transformed data for both targets\n",
    "X_train_d = X_train_transformed\n",
    "X_train_f = X_train_transformed\n",
    "X_test_d = X_test_transformed\n",
    "X_test_f = X_test_transformed\n",
    "\n",
    "X_train_d.toarray()\n",
    "\n",
    "X_test_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe938d75-15ef-4b55-8305-8d8a55823898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d1f3bf-0165-4da3-a319-c4ca6480d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    accuracy = 100 - mape\n",
    "    print(f\"{model_name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, RÂ²: {r2:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee935cc-1ec1-46e3-916f-5b6a95675054",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('lgbm', LGBMRegressor(n_estimators=10, learning_rate=0.05, max_depth=5, subsample=0.8)),\n",
    "    ('xgb', XGBRegressor(n_estimators=10, learning_rate=0.05, max_depth=5, subsample=0.8)),\n",
    "    ('rf', RandomForestRegressor(n_estimators=10, max_depth=10)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=10, learning_rate=0.05, max_depth=5))\n",
    "]\n",
    "\n",
    "# Meta-model (Linear Regression for final prediction)\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Stacking Regressors for Demand and Discount\n",
    "demand_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "discount_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc2aee0-74fb-4757-8b64-545be6ba2147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 58480, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 141.776563\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 141.474872\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 141.926765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1266\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 141.956782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1264\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 141.763652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 141.760745\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 58480, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 10.000427\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 10.000107\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 9.999252\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1266\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 9.980335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1264\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 10.036230\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 46784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 9.986213\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;lgbm&#x27;,\n",
       "                               LGBMRegressor(learning_rate=0.05, max_depth=5,\n",
       "                                             n_estimators=10, subsample=0.8)),\n",
       "                              (&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None,\n",
       "                                            feat...\n",
       "                                            max_delta_step=None, max_depth=5,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=10, n_jobs=None,\n",
       "                                            num_parallel_tree=None, ...)),\n",
       "                              (&#x27;rf&#x27;,\n",
       "                               RandomForestRegressor(max_depth=10,\n",
       "                                                     n_estimators=10)),\n",
       "                              (&#x27;gb&#x27;,\n",
       "                               GradientBoostingRegressor(learning_rate=0.05,\n",
       "                                                         max_depth=5,\n",
       "                                                         n_estimators=10))],\n",
       "                  final_estimator=LinearRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;lgbm&#x27;,\n",
       "                               LGBMRegressor(learning_rate=0.05, max_depth=5,\n",
       "                                             n_estimators=10, subsample=0.8)),\n",
       "                              (&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None,\n",
       "                                            feat...\n",
       "                                            max_delta_step=None, max_depth=5,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=10, n_jobs=None,\n",
       "                                            num_parallel_tree=None, ...)),\n",
       "                              (&#x27;rf&#x27;,\n",
       "                               RandomForestRegressor(max_depth=10,\n",
       "                                                     n_estimators=10)),\n",
       "                              (&#x27;gb&#x27;,\n",
       "                               GradientBoostingRegressor(learning_rate=0.05,\n",
       "                                                         max_depth=5,\n",
       "                                                         n_estimators=10))],\n",
       "                  final_estimator=LinearRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.8)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=10,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, n_estimators=10)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=10)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('lgbm',\n",
       "                               LGBMRegressor(learning_rate=0.05, max_depth=5,\n",
       "                                             n_estimators=10, subsample=0.8)),\n",
       "                              ('xgb',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None,\n",
       "                                            feat...\n",
       "                                            max_delta_step=None, max_depth=5,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=10, n_jobs=None,\n",
       "                                            num_parallel_tree=None, ...)),\n",
       "                              ('rf',\n",
       "                               RandomForestRegressor(max_depth=10,\n",
       "                                                     n_estimators=10)),\n",
       "                              ('gb',\n",
       "                               GradientBoostingRegressor(learning_rate=0.05,\n",
       "                                                         max_depth=5,\n",
       "                                                         n_estimators=10))],\n",
       "                  final_estimator=LinearRegression())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_model.fit(X_train_f, y_train_f)\n",
    "discount_model.fit(X_train_d, y_train_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638b628f-4be6-43fd-9d19-d58664e29cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_demand_pred = demand_model.predict(X_test_f)\n",
    "y_discount_pred = discount_model.predict(X_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf38a8d-5715-4b15-9b37-c4cce8610b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Demand Forecast Model - MAE: 7.50, RMSE: 8.71, RÂ²: 0.9936, Accuracy: 52.96%\n",
      "Ensemble Discount Model - MAE: 5.96, RMSE: 7.04, RÂ²: -0.0001, Accuracy: -inf%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test_f, y_demand_pred, 'Ensemble Demand Forecast Model')\n",
    "evaluate_model(y_test_d, y_discount_pred, 'Ensemble Discount Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f2daf53-c9c0-45cd-b977-46afea656c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained models\n",
    "joblib.dump(demand_model, 'demand_forecast_model.pkl')\n",
    "joblib.dump(discount_model, 'discount_prediction_model.pkl')\n",
    "\n",
    "print(\"Models saved successfully!\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load trained models\n",
    "demand_model = joblib.load('demand_forecast_model.pkl')\n",
    "discount_model = joblib.load('discount_prediction_model.pkl')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6823b24f-3e41-4e7e-97f5-0370d0375d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features:\n",
      "         Date Store ID Product ID  Inventory Level  Units Sold  Units Ordered  \\\n",
      "0  01-01-2023     S001      P0001            231.0       127.0           55.0   \n",
      "1  01-01-2023     S001      P0002            204.0       150.0           66.0   \n",
      "\n",
      "   Price Weather Condition  Competitor Pricing Seasonality  \n",
      "0  33.50             Rainy               29.69      Autumn  \n",
      "1  63.01             Sunny               66.16      Autumn  \n",
      "\n",
      "Predicted Demand Forecast:\n",
      "[133.16866403 153.54259629]\n",
      "\n",
      "Predicted Discount:\n",
      "[ 9.99009799 10.01343142]\n",
      "\n",
      "Preprocessor expects features:\n",
      "['Date' 'Store ID' 'Product ID' 'Inventory Level' 'Units Sold'\n",
      " 'Units Ordered' 'Price' 'Weather Condition' 'Competitor Pricing'\n",
      " 'Seasonality' 'Base Cost']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample input data (same as your example)\n",
    "data = pd.DataFrame([\n",
    "    {\n",
    "        'Date': '01-01-2023',\n",
    "        'Store ID': 'S001',\n",
    "        'Product ID': 'P0001',\n",
    "        'Inventory Level': 231.0,\n",
    "        'Units Sold': 127.0,\n",
    "        'Units Ordered': 55.0,\n",
    "        'Price': 33.50,\n",
    "        'Weather Condition': 'Rainy',\n",
    "        'Competitor Pricing': 29.69,\n",
    "        'Seasonality': 'Autumn'\n",
    "    },\n",
    "    {\n",
    "        'Date': '01-01-2023',\n",
    "        'Store ID': 'S001',\n",
    "        'Product ID': 'P0002',\n",
    "        'Inventory Level': 204.0,\n",
    "        'Units Sold': 150.0,\n",
    "        'Units Ordered': 66.0,\n",
    "        'Price': 63.01,\n",
    "        'Weather Condition': 'Sunny',\n",
    "        'Competitor Pricing': 66.16,\n",
    "        'Seasonality': 'Autumn'\n",
    "    }\n",
    "])\n",
    "\n",
    "# Drop target columns if present (safe even if not present)\n",
    "input_features = data.drop(columns=['Demand_Forecast', 'Discount'], errors='ignore')\n",
    "\n",
    "print(\"Input features:\")\n",
    "print(input_features)\n",
    "\n",
    "# Transform inputs using your preprocessor\n",
    "X_input = preprocessor.transform(input_features)\n",
    "\n",
    "# Predict demand and discount using the trained models\n",
    "predicted_demand = demand_model.predict(X_input)\n",
    "predicted_discount = discount_model.predict(X_input)\n",
    "\n",
    "print(\"\\nPredicted Demand Forecast:\")\n",
    "print(predicted_demand)\n",
    "\n",
    "print(\"\\nPredicted Discount:\")\n",
    "print(predicted_discount)\n",
    "\n",
    "# Optional: Check what features the preprocessor expects\n",
    "print(\"\\nPreprocessor expects features:\")\n",
    "print(preprocessor.feature_names_in_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb03be-4edd-4afe-9c07-ada857443908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
